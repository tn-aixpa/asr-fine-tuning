{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3444773d-4c79-44e1-a020-667c49256688",
   "metadata": {},
   "outputs": [],
   "source": [
    "import  digitalhub as dh\n",
    "\n",
    "project = dh.get_or_create_project(\"llmpa-test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a982148-b80a-459e-84a1-c5cdd2b043ca",
   "metadata": {},
   "source": [
    "## 1. Create and Preprocess dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34b5d0a-ff0a-4df9-8760-c7667cf97786",
   "metadata": {},
   "outputs": [],
   "source": [
    "func = project.new_function(\n",
    "    name=\"create-dataset\", \n",
    "    kind=\"python\", \n",
    "    python_version=\"PYTHON3_10\", \n",
    "    code_src=\"src/fine_tuning_seq2seq.py\",  \n",
    "    handler=\"preprocess_dataset\",\n",
    "    requirements=[\"datasets[audio]==3.6.0\", \"transformers==4.56.1\", \"torch==2.8.0\", \"accelerate==1.10.1\", \"evaluate==0.4.5\", \"jiwer==4.0.0\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8dd6b4-d5e2-4b9c-ae6c-490cc5974b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_run = func.run(action=\"job\",\n",
    "                     parameters={\n",
    "                         \"model_id\": \"openai/whisper-small\",\n",
    "                         \"artifact_name\": \"audio-dataset\",\n",
    "                         \"dataset_name\": \"mozilla-foundation/common_voice_17_0\",\n",
    "                         \"language\": \"Italian\",\n",
    "                         \"language_code\": \"it\",\n",
    "                         \"max_train_samples\": 100,\n",
    "                         \"max_eval_samples\": 100\n",
    "                     },\n",
    "                     secrets=[\"HF_TOKEN\"],\n",
    "                     envs=[\n",
    "                        {\"name\": \"HF_HOME\", \"value\": \"shared/data/huggingface\"},\n",
    "                        {\"name\": \"TRANSFORMERS_CACHE\", \"value\":  \"shared/data/huggingface\"}\n",
    "                     ],\n",
    "                     volumes=[{\n",
    "                        \"volume_type\": \"persistent_volume_claim\",\n",
    "                        \"name\": \"volume-llmpa\",\n",
    "                        \"mount_path\": \"/shared/data\",\n",
    "                        \"spec\": { \"size\": \"300Gi\" }}]\n",
    "\t\t\t\t\t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d251900a-09b4-4ae6-bf1c-f04b3b0c3bc0",
   "metadata": {},
   "source": [
    "## 2. Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de8703c-ee9c-42e4-a0aa-ba77eb01f7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "func = project.new_function(\n",
    "    name=\"train-whisper\", \n",
    "    kind=\"python\", \n",
    "    python_version=\"PYTHON3_10\", \n",
    "    code_src=\"src/fine_tuning_seq2seq.py\",  \n",
    "    handler=\"train_and_log_model\",\n",
    "    requirements=[\"datasets[audio]==3.6.0\", \"transformers==4.52.0\", \"torch==2.8.0\", \"accelerate==1.10.1\", \"evaluate==0.4.5\", \"jiwer==4.0.0\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfd73c1-62e5-4ddc-be42-78a01887efe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_run = func.run(action=\"job\",\n",
    "                     parameters={\n",
    "                         \"model_id\": \"openai/whisper-small\",\n",
    "                         \"model_name\": \"whisper-ft\",\n",
    "                         \"dataset_name\": \"mozilla-foundation/common_voice_11_0\",\n",
    "                         \"language\": \"Italian\",\n",
    "                         \"language_code\": \"it\",\n",
    "                         \"max_train_samples\": 100,\n",
    "                         \"max_eval_samples\": 100,\n",
    "                         \"eval_steps\": 100,\n",
    "                         \"save_steps\": 100,\n",
    "                         \"max_steps\": 500,\n",
    "                         \"warmup_steps\": 50\n",
    "                     },\n",
    "                     profile=\"1xa100\",\n",
    "                     secrets=[\"HF_TOKEN\"],\n",
    "                     envs=[\n",
    "                        {\"name\": \"HF_HOME\", \"value\": \"shared/data/huggingface\"},\n",
    "                        {\"name\": \"TRANSFORMERS_CACHE\", \"value\":  \"shared/data/huggingface\"}\n",
    "                     ],\n",
    "                     volumes=[{\n",
    "                        \"volume_type\": \"persistent_volume_claim\",\n",
    "                        \"name\": \"volume-llmpa\",\n",
    "                        \"mount_path\": \"/shared/data\",\n",
    "                        \"spec\": { \"size\": \"100Gi\" }}]\n",
    "\t\t\t\t\t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ad16af-be01-4903-b11b-d74544bfda8e",
   "metadata": {},
   "source": [
    "## 3. Convert to FasterWhisper\n",
    "download model, convert to FasterWhisper and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aeb3a80-fe09-40e0-9fc8-db5e7d6b0231",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = project.get_model(\"whisper-ft\")\n",
    "model.download(\"./model/whisper-ft\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7b7309-6677-4be0-a32b-36a259aae331",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pip install faster-whisper transformers torch==2.8.0\n",
    "wget -O audio.wav https://github.com/user-attachments/assets/711d1279-6af9-4c6c-a052-e59e7730b757"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57163f35-271d-40f4-8125-6927d7d98c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ctranslate2.converters import TransformersConverter\n",
    "\n",
    "tc = TransformersConverter(\"./model/whisper-ft\", copy_files=['tokenizer.json', 'preprocessor_config.json', 'README.md'])\n",
    "tc.convert('./model/whisper-ft2', quantization=\"float16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8d25bf-0fa9-4100-a44d-03dafd1c6e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from faster_whisper import WhisperModel\n",
    "\n",
    "model = WhisperModel('./model/faster-whisper-ft', device=\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5eca351-f0d5-46f7-b1fa-cc4ab58dd2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "segments, info = model.transcribe(\"audio.wav\", beam_size=5)\n",
    "\n",
    "print(\"Detected language '%s' with probability %f\" % (info.language, info.language_probability))\n",
    "\n",
    "for segment in segments:\n",
    "    print(\"[%.2fs -> %.2fs] %s\" % (segment.start, segment.end, segment.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06580935-8e12-4bb0-971b-08ae7de182f7",
   "metadata": {},
   "source": [
    "## 4. Log FasterWhisper model and deploy with KubeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951cdf78-be73-4c12-9aba-db189f9fcca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = project.log_model(\"faster-whisper-ft\", kind=\"huggingface\", framework=\"FasterWhisper\", source=\"./model/faster-whisper-ft/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f25ef1-21f3-41a0-9fbe-0f5fb64d46d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pip install faster-whisper torch==2.8.0 transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92413626-dd8b-495c-8bcf-607d77369d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(base_url=f\"http://kubeai:80/openai/v1\", api_key=\"ignore\")\n",
    "audio_file= open(\"audio.wav\", \"rb\")\n",
    "\n",
    "transcription = client.audio.transcriptions.create(\n",
    "    model=f\"model-9b9cc6b85c16488c9d67800e635b7d3d\", \n",
    "    file=audio_file\n",
    ")\n",
    "\n",
    "print(transcription.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
