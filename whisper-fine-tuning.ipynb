{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3444773d-4c79-44e1-a020-667c49256688",
   "metadata": {},
   "outputs": [],
   "source": [
    "import  digitalhub as dh\n",
    "\n",
    "project = dh.get_or_create_project(\"faudit-classifier-demo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a982148-b80a-459e-84a1-c5cdd2b043ca",
   "metadata": {},
   "source": [
    "## 1. Create and Preprocess dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34b5d0a-ff0a-4df9-8760-c7667cf97786",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    func = project.get_function(\"create-dataset\")\n",
    "except:\n",
    "    func = project.new_function(\n",
    "        name=\"create-dataset\", \n",
    "        kind=\"python\", \n",
    "        python_version=\"PYTHON3_10\", \n",
    "        code_src=\"src/fine_tuning_seq2seq.py\",  \n",
    "        handler=\"preprocess_dataset\",\n",
    "        requirements=[\"datasets[audio]==3.6.0\", \"transformers==4.56.1\", \"torch==2.8.0\", \"accelerate==1.10.1\", \"evaluate==0.4.5\", \"jiwer==4.0.0\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8dd6b4-d5e2-4b9c-ae6c-490cc5974b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_run = func.run(action=\"job\",\n",
    "                     parameters={\n",
    "                         \"model_id\": \"openai/whisper-small\",\n",
    "                         \"artifact_name\": \"audio-dataset\",\n",
    "                         \"dataset_name\": \"fsicoli/common_voice_17_0\",\n",
    "                         \"language\": \"Italian\",\n",
    "                         \"language_code\": \"it\",\n",
    "                         \"max_train_samples\": 100,\n",
    "                         \"max_eval_samples\": 100\n",
    "                     },\n",
    "                     secrets=[\"HF_TOKEN\"],\n",
    "                     envs=[\n",
    "                        {\"name\": \"HF_HOME\", \"value\": \"/local_data/huggingface\"},\n",
    "                        {\"name\": \"TRANSFORMERS_CACHE\", \"value\":  \"/local_data/huggingface\"}\n",
    "                     ],\n",
    "                     volumes=[{\n",
    "                        \"volume_type\": \"persistent_volume_claim\",\n",
    "                        \"name\": \"volume-llmpa\",\n",
    "                        \"mount_path\": \"/local_data\",\n",
    "                        \"spec\": { \"size\": \"300Gi\" }}]\n",
    "\t\t\t\t\t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d251900a-09b4-4ae6-bf1c-f04b3b0c3bc0",
   "metadata": {},
   "source": [
    "## 2. Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de8703c-ee9c-42e4-a0aa-ba77eb01f7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    func = project.get_function(\"train-whisper\")\n",
    "except:\n",
    "    func = project.new_function(\n",
    "        name=\"train-whisper\", \n",
    "        kind=\"python\", \n",
    "        python_version=\"PYTHON3_10\", \n",
    "        code_src=\"src/fine_tuning_seq2seq.py\",  \n",
    "        handler=\"train_and_log_model\",\n",
    "        requirements=[\"datasets[audio]==3.6.0\", \"transformers==4.52.0\", \"torch==2.8.0\", \"accelerate==1.10.1\", \"evaluate==0.4.5\", \"jiwer==4.0.0\"]\n",
    "    )\n",
    "    build_run = func.run(action=\"build\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfd73c1-62e5-4ddc-be42-78a01887efe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_run = func.run(action=\"job\",\n",
    "                     parameters={\n",
    "                         \"model_id\": \"openai/whisper-small\",\n",
    "                         \"model_name\": \"whisper-ft\",\n",
    "                         \"dataset_name\": \"fsicoli/common_voice_17_0\",\n",
    "                         \"language\": \"Italian\",\n",
    "                         \"language_code\": \"it\",\n",
    "                         \"max_train_samples\": 100,\n",
    "                         \"max_eval_samples\": 100,\n",
    "                         \"eval_steps\": 100,\n",
    "                         \"save_steps\": 100,\n",
    "                         \"max_steps\": 500,\n",
    "                         \"warmup_steps\": 50\n",
    "                     },\n",
    "                     profile=\"1xa100\",\n",
    "                     secrets=[\"HF_TOKEN\"],\n",
    "                     envs=[\n",
    "                        {\"name\": \"HF_HOME\", \"value\": \"/local_data/huggingface\"},\n",
    "                        {\"name\": \"TRANSFORMERS_CACHE\", \"value\":  \"/local_data/huggingface\"}\n",
    "                     ],\n",
    "                     volumes=[{\n",
    "                        \"volume_type\": \"persistent_volume_claim\",\n",
    "                        \"name\": \"volume-llmpa\",\n",
    "                        \"mount_path\": \"/local_data\",\n",
    "                        \"spec\": { \"size\": \"100Gi\" }}]\n",
    "\t\t\t\t\t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ad16af-be01-4903-b11b-d74544bfda8e",
   "metadata": {},
   "source": [
    "## 3. Convert to FasterWhisper\n",
    "download model, convert to FasterWhisper and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aeb3a80-fe09-40e0-9fc8-db5e7d6b0231",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = project.get_model(\"whisper-ft\")\n",
    "model.download(\"./model/whisper-ft\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7b7309-6677-4be0-a32b-36a259aae331",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pip install faster-whisper transformers torch==2.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd8fc20-0299-43b1-9700-97da6c1e91df",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O audio.wav https://github.com/user-attachments/assets/711d1279-6af9-4c6c-a052-e59e7730b757"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57163f35-271d-40f4-8125-6927d7d98c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ctranslate2.converters import TransformersConverter\n",
    "\n",
    "tc = TransformersConverter(\"./model/whisper-ft\", copy_files=['tokenizer.json', 'preprocessor_config.json', 'README.md'])\n",
    "tc.convert('./model/faster-whisper-ft', quantization=\"float16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8d25bf-0fa9-4100-a44d-03dafd1c6e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from faster_whisper import WhisperModel\n",
    "\n",
    "model = WhisperModel('./model/faster-whisper-ft', device=\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5eca351-f0d5-46f7-b1fa-cc4ab58dd2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "segments, info = model.transcribe(\"audio.wav\", beam_size=5)\n",
    "\n",
    "print(\"Detected language '%s' with probability %f\" % (info.language, info.language_probability))\n",
    "\n",
    "for segment in segments:\n",
    "    print(\"[%.2fs -> %.2fs] %s\" % (segment.start, segment.end, segment.text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (OltreAI)",
   "language": "python",
   "name": "python3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
